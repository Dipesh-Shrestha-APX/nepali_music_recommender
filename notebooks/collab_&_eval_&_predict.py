# -*- coding: utf-8 -*-
"""Collab & Eval & Predict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SX34WpuuJc7ICxJTB7JS_VE4TXlLmEqE
"""

pip install implicit

import pandas as pd
import numpy as np
from implicit.als import AlternatingLeastSquares
from scipy.sparse import coo_matrix
import pickle
import os

def load_tracks_and_generate_interactions(song_csv, interaction_csv):
    # Load song metadata
    tracks_df = pd.read_csv(song_csv)

    # Add track_id column if missing
    if 'track_id' not in tracks_df.columns:
        tracks_df["track_id"] = [f"Track_{i+1}" for i in range(len(tracks_df))]

    # Load user interaction dataset
    interactions_df = pd.read_csv(interaction_csv)

    # Ensure types are consistent
    tracks_df['track_id'] = tracks_df['track_id'].astype(str)
    interactions_df['track_id'] = interactions_df['track_id'].astype(str)
    interactions_df['user_id'] = interactions_df['user_id'].astype(str)

    # Filter interactions to only include tracks present in tracks_df
    valid_track_ids = set(tracks_df['track_id'])
    interactions_df = interactions_df[interactions_df['track_id'].isin(valid_track_ids)]

    # Filter users and tracks with sufficient interactions
    min_interactions = 5  # Adjust as needed
    user_counts = interactions_df['user_id'].value_counts()
    track_counts = interactions_df['track_id'].value_counts()
    valid_users = user_counts[user_counts >= min_interactions].index
    valid_tracks = track_counts[track_counts >= min_interactions].index
    interactions_df = interactions_df[
        (interactions_df['user_id'].isin(valid_users)) &
        (interactions_df['track_id'].isin(valid_tracks))
    ]

    # Extract user and track IDs after filtering
    user_ids = interactions_df['user_id'].unique().tolist()
    track_ids = interactions_df['track_id'].unique().tolist()

    print(f"Number of users after filtering: {len(user_ids)}")
    print(f"Number of tracks after filtering: {len(track_ids)}")

    return tracks_df, interactions_df, user_ids, track_ids

def prepare_matrix(interactions_df, user_ids, track_ids):
    # Create mappings for valid users and tracks
    user_map = {uid: idx for idx, uid in enumerate(user_ids)}
    track_map = {tid: idx for idx, tid in enumerate(track_ids)}

    rows = []
    cols = []
    data = []
    for u, t, p in zip(interactions_df['user_id'], interactions_df['track_id'], interactions_df['play_count']):
        if u in user_map and t in track_map:  # Double-check validity
            rows.append(user_map[u])
            cols.append(track_map[t])
            data.append(p)

    matrix = coo_matrix((data, (rows, cols)), shape=(len(user_ids), len(track_ids)))

    # Verify matrix dimensions
    print(f"Matrix shape: {matrix.shape}")
    print(f"Number of non-zero entries: {matrix.nnz}")

    return matrix, user_map, track_map

def train_als(matrix, factors=50, iterations=20, test_size=0.2):
    rng = np.random.default_rng(42)
    train = matrix.copy()
    test_idx = rng.choice(np.arange(matrix.nnz), size=int(matrix.nnz * test_size), replace=False)
    train.data[test_idx] = 0
    train.eliminate_zeros()

    test = coo_matrix(matrix.shape)
    test.row = matrix.row[test_idx]
    test.col = matrix.col[test_idx]
    test.data = matrix.data[test_idx]

    model = AlternatingLeastSquares(factors=factors, iterations=iterations, random_state=42)
    model.fit(train.T)

    return model, train.tocsr(), test.tocsr()

def precision_at_k(model, test_matrix, k=10, threshold=3.5):
    scores = []
    for user_idx in range(test_matrix.shape[0]):
        true_items = test_matrix[user_idx].indices[test_matrix[user_idx].data >= threshold]
        if len(true_items) == 0:
            continue
        item_ids, _ = model.recommend(user_idx, test_matrix, N=k, filter_already_liked_items=False)
        rec_items = item_ids
        hit_count = len(set(rec_items) & set(true_items))
        scores.append(hit_count / k)
    return np.mean(scores) if scores else 0.0

def mean_average_precision(model, test_matrix, k=10, threshold=3.5):
    scores = []
    for user_idx in range(test_matrix.shape[0]):
        true_items = test_matrix[user_idx].indices[test_matrix[user_idx].data >= threshold]
        if len(true_items) == 0:
            continue
        item_ids, _ = model.recommend(user_idx, test_matrix, N=k, filter_already_liked_items=False)
        hit = 0.0
        score = 0.0
        for i, item in enumerate(item_ids):
            if item in true_items:
                hit += 1.0
                score += hit / (i + 1.0)
        scores.append(score / len(true_items) if true_items.any() else 0.0)
    return np.mean(scores) if scores else 0.0

def save_model(model, user_map, track_map, train_matrix, path='/content/drive/MyDrive/collaborative/als_model.pkl'):
    """
    Save the ALS model, user_map, and track_map, ensuring both maps align with train_matrix.

    Parameters:
    - model: Trained ALS model.
    - user_map: Dictionary mapping user IDs to matrix indices.
    - track_map: Dictionary mapping track IDs to matrix indices.
    - train_matrix: The training user-item matrix (CSR format).
    - path: Path to save the model.
    """
    # Filter user_map and track_map to match train_matrix dimensions
    valid_user_indices = set(range(train_matrix.shape[0]))
    valid_track_indices = set(range(train_matrix.shape[1]))
    filtered_user_map = {user_id: idx for user_id, idx in user_map.items() if idx in valid_user_indices}
    filtered_track_map = {track_id: idx for track_id, idx in track_map.items() if idx in valid_track_indices}

    print(f"Filtered user_map size: {len(filtered_user_map)}")
    print(f"Filtered track_map size: {len(filtered_track_map)}")

    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, 'wb') as f:
        pickle.dump({'model': model, 'user_map': filtered_user_map, 'track_map': filtered_track_map}, f)
    print(f"Model saved to {path}")

if __name__ == "__main__":
    song_csv = '/content/DATASET FOR TRAINING.csv'
    interaction_csv = '/content/drive/MyDrive/content_based/user_interactions3.csv'
    tracks_df, interactions_df, user_ids, track_ids = load_tracks_and_generate_interactions(song_csv, interaction_csv)

    print(f"Number of users: {len(user_ids)}")
    print(f"Number of tracks: {len(track_ids)}")

    matrix, user_map, track_map = prepare_matrix(interactions_df, user_ids, track_ids)

    print(f"Number of users in user_map: {len(user_map)}")
    print(f"Number of tracks in track_map: {len(track_map)}")

    model, train_matrix, test_matrix = train_als(matrix)

    print(f"Train matrix shape: {train_matrix.shape}")
    print(f"Model user factors shape: {model.user_factors.shape}")
    print(f"Model item factors shape: {model.item_factors.shape}")

    precision = precision_at_k(model, test_matrix)
    map_score = mean_average_precision(model, test_matrix)

    save_model(model, user_map, track_map, train_matrix)

    print("\nEvaluation Results:")
    print(f"{'Precision@10':<15} {precision:.4f}")
    print(f"{'MAP':<15} {map_score:.4f}")

# !pip install implicit

import pandas as pd
import pickle
from scipy.sparse import coo_matrix

def load_model(model_path='/content/drive/MyDrive/collaborative/als_model.pkl'):
    with open(model_path, 'rb') as f:
        saved_data = pickle.load(f)
    return saved_data['model'], saved_data['user_map'], saved_data['track_map']

def get_user_recommendations(user_id, model, user_map, track_map, tracks_df, interactions_df, n=10):
    if user_id not in user_map:
        return f"User {user_id} not found."

    user_idx = user_map[user_id]
    if user_idx >= model.user_factors.shape[0]:
        return f"User index {user_idx} out of bounds."

    user_interactions = interactions_df[interactions_df['user_id'] == user_id]
    if user_interactions.empty:
        return f"No interactions for user {user_id}."

    num_items = model.item_factors.shape[1]
    cols = []
    data = []
    for tid, play_count in zip(user_interactions['track_id'], user_interactions['play_count']):
        if tid in track_map and track_map[tid] < num_items:
            cols.append(track_map[tid])
            data.append(play_count)

    if not cols:
        return f"No valid track interactions for user {user_id}."

    user_matrix = coo_matrix(([play_count for play_count in data], ([0] * len(cols), cols)), shape=(1, num_items)).tocsr()

    try:
        item_ids, _ = model.recommend(user_idx, user_matrix, N=n, filter_already_liked_items=True)
    except Exception as e:
        return f"Error generating recommendations: {str(e)}"

    track_id_map = {idx: tid for tid, idx in track_map.items()}
    recommended_track_ids = [track_id_map[i] for i in item_ids if i in track_id_map]

    recommended_songs = tracks_df[tracks_df['track_id'].isin(recommended_track_ids)][['track_id', 'title', 'artist']]
    ordered_recommendations = pd.DataFrame({'track_id': recommended_track_ids}).merge(
        recommended_songs, on='track_id', how='left'
    )

    return ordered_recommendations[['title', 'artist']].rename(
        columns={'title': 'track_name', 'artist': 'artist_name'}
    ).to_dict('records')

if __name__ == "__main__":
    model_path = '/content/drive/MyDrive/collaborative/als_model.pkl'
    song_csv = '/content/DATASET FOR TRAINING.csv'
    interaction_csv = '/content/drive/MyDrive/content_based/user_interactions3.csv'

    tracks_df = pd.read_csv(song_csv)
    if 'track_id' not in tracks_df.columns:
        tracks_df["track_id"] = [f"Track_{i+1}" for i in range(len(tracks_df))]
    tracks_df['track_id'] = tracks_df['track_id'].astype(str)

    interactions_df = pd.read_csv(interaction_csv)
    interactions_df['track_id'] = interactions_df['track_id'].astype(str)
    interactions_df['user_id'] = interactions_df['user_id'].astype(str)

    model, user_map, track_map = load_model(model_path)

    user_id = "User_30"
    recommendations = get_user_recommendations(user_id, model, user_map, track_map, tracks_df, interactions_df)

    if isinstance(recommendations, str):
        print(recommendations)
    else:
        print(f"Top 10 song recommendations for user {user_id}:")
        for i, song in enumerate(recommendations, 1):
            print(f"{i}. {song['track_name']} by {song['artist_name']}")

